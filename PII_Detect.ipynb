{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMWBXpoAnClGFIeYOQ4+ttq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjdileep/PII-Detect/blob/main/PII_Detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96OpfcTOv37U",
        "outputId": "49c9cf72-3b35-4e85-b402-8cf11a78672c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n",
        "!pip install datasets\n",
        "!pip install accelerate -U\n",
        "!pip uninstall tensorflow -y\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "17Y09cYnO0Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Get the number of CPU cores\n",
        "cpu_cores = multiprocessing.cpu_count()"
      ],
      "metadata": {
        "id": "8ORgDUUTPPQt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "EVEImEfrv-Yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8bbed4-9486-439a-ae4b-c3769d5fb868"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the dataset"
      ],
      "metadata": {
        "id": "s6dW8m_nsYSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "!wget http://#######.us-east-2.compute.amazonaws.com:8000/mixtral-8x7b-v1_names_fixed.json\n",
        "!wget http://#######.us-east-2.compute.amazonaws.com:8000/mpware_mixtral8x7b_v1.1-no-i-username_names_fixed.json\n",
        "!wget http://#######.us-east-2.compute.amazonaws.com:8000/vw_moth_pii_dataset_fixed_names_fixed.json\n",
        "!wget http://#######.us-east-2.compute.amazonaws.com:8000/vw_pj_moredata_dataset_fixed_names_fixed.json\n",
        "!wget http://#######.us-east-2.compute.amazonaws.com:8000/illi_data_names_fixed.json\n",
        "!wget http://#######.us-east-2.compute.amazonaws.com:8000/train.json\n",
        "!wget http://#######.us-east-2.compute.amazonaws.com:8000/enable.txt\n",
        "!cp *.json '/content/drive/MyDrive/AIML/PII Detect'\n",
        "!cp *.txt '/content/drive/MyDrive/AIML/PII Detect'\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "dh_C4R4twENN",
        "outputId": "f8a5a8c6-50c8-485b-a4df-c1f36f483ba3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n!wget http://ec2-3-128-179-24.us-east-2.compute.amazonaws.com:8000/mixtral-8x7b-v1_names_fixed.json\\n!wget http://ec2-3-128-179-24.us-east-2.compute.amazonaws.com:8000/mpware_mixtral8x7b_v1.1-no-i-username_names_fixed.json\\n!wget http://ec2-3-128-179-24.us-east-2.compute.amazonaws.com:8000/vw_moth_pii_dataset_fixed_names_fixed.json\\n!wget http://ec2-3-128-179-24.us-east-2.compute.amazonaws.com:8000/vw_pj_moredata_dataset_fixed_names_fixed.json\\n!wget http://ec2-3-128-179-24.us-east-2.compute.amazonaws.com:8000/illi_data_names_fixed.json\\n!wget http://ec2-3-128-179-24.us-east-2.compute.amazonaws.com:8000/train.json\\n!wget http://ec2-3-128-179-24.us-east-2.compute.amazonaws.com:8000/enable.txt\\n!cp *.json '/content/drive/MyDrive/AIML/PII Detect'\\n!cp *.txt '/content/drive/MyDrive/AIML/PII Detect'\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enable_eng_wordlist = set()\n",
        "with open(\"/content/drive/MyDrive/AIML/PII Detect/enable.txt\", \"r\") as f:\n",
        "    line = f.readline().strip()\n",
        "    while line:\n",
        "        enable_eng_wordlist.add(line)\n",
        "        line = f.readline().strip()\n"
      ],
      "metadata": {
        "id": "cU3-ROBkw-7K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TRAINING_MODEL_PATH = \"microsoft/deberta-v3-large\"  # your model path\n",
        "TRAINING_MAX_LENGTH = 1280  # I use 1280 locally\n",
        "base_location = \"/content/drive/MyDrive/AIML/PII Detect/\"\n",
        "OUTPUT_DIR = base_location+'deberta_v3_large_2stepped'  # your output path\n",
        "fill_label = \"O\"#ignore_label"
      ],
      "metadata": {
        "id": "bxPZaJY-xSqC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import argparse\n",
        "from itertools import chain\n",
        "from functools import partial\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
        "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
        "from transformers import PreTrainedModel, PretrainedConfig\n",
        "import datasets\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from datasets import Dataset, features\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def set_random_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "set_random_seeds(42)\n",
        "\n",
        "from nltk.corpus import words\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "PK_2QQobxn5u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n"
      ],
      "metadata": {
        "id": "nx8_peVSxqA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = set(['B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT','B-PHONE_NUM','B-STREET_ADDRESS','B-URL_PERSONAL','B-USERNAME', 'I-ID_NUM','I-NAME_STUDENT','I-PHONE_NUM','I-STREET_ADDRESS','I-URL_PERSONAL','O'])\n",
        "def is_exists(labels, targets):\n",
        "    labels = set(labels)\n",
        "    targets = set(targets)\n",
        "    if labels.intersection(targets):\n",
        "        return True\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "l-B2U1hbwoWV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Dataset\n"
      ],
      "metadata": {
        "id": "eMZ0N6m9sf46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = ['B-ID_NUM','B-PHONE_NUM','B-STREET_ADDRESS','B-URL_PERSONAL','B-USERNAME']\n",
        "\n",
        "nicollas = json.load(open(base_location+\"mixtral-8x7b-v1_names_fixed.json\"))\n",
        "l = len(nicollas)\n",
        "nicollas_filtered = []\n",
        "for doc in nicollas:\n",
        "    if is_exists(doc[\"labels\"], targets+['B-NAME_STUDENT']):\n",
        "        nicollas_filtered.append(doc)\n",
        "nicollas = nicollas_filtered\n",
        "print(f\"nicollas size({l}):\", len(nicollas))\n",
        "\n",
        "\n",
        "mpware = json.load(open(base_location+\"mpware_mixtral8x7b_v1.1-no-i-username_names_fixed.json\"))\n",
        "mpware_filtered = []\n",
        "for doc in mpware:\n",
        "    if is_exists(doc[\"labels\"], targets+['B-NAME_STUDENT']):\n",
        "        mpware_filtered.append(doc)\n",
        "mpware = mpware_filtered\n",
        "print(\"mpware size:\", len(mpware))\n",
        "\n",
        "moth = json.load(open(base_location+\"vw_moth_pii_dataset_fixed_names_fixed.json\"))\n",
        "moth_filtered = []\n",
        "for doc in moth:\n",
        "    if is_exists(doc[\"labels\"], targets+['B-NAME_STUDENT']):\n",
        "        moth_filtered.append(doc)\n",
        "moth = moth_filtered\n",
        "print(\"moth size:\", len(moth))\n",
        "\n",
        "\n",
        "pj = json.load(open(base_location+\"vw_pj_moredata_dataset_fixed_names_fixed.json\"))\n",
        "pj_filtered = []\n",
        "for doc in pj:\n",
        "    if is_exists(doc[\"labels\"], targets+['B-NAME_STUDENT']):\n",
        "        pj_filtered.append(doc)\n",
        "pj = pj_filtered\n",
        "print(\"pj size:\", len(pj))\n",
        "\n",
        "\n",
        "filtered_docs = [1000185,1000988,1001022,1001093,1002098,1002141,1002211,1002246,1002398,1002411,1002599,1002660,1002809,1002854,1002926,1002970,1003005,1003149,1003211]\n",
        "illi_data_names_fixed = []\n",
        "for doc in json.load(open(base_location+\"illi_data_names_fixed.json\")):\n",
        "    if doc[\"document\"] not in filtered_docs:\n",
        "        illi_data_names_fixed.append(doc)\n",
        "illi_data_names_fixed_filtered = []\n",
        "for doc in illi_data_names_fixed:\n",
        "    if is_exists(doc[\"labels\"], targets+['B-NAME_STUDENT']):\n",
        "        illi_data_names_fixed_filtered.append(doc)\n",
        "illi_data = illi_data_names_fixed_filtered\n",
        "print(\"illi_data size:\", len(illi_data))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FcE3qNAwpDv",
        "outputId": "5d310170-d572-43c3-af40-1ee5e986e451"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nicollas size(2355): 2355\n",
            "mpware size: 2322\n",
            "moth size: 4423\n",
            "pj size: 1999\n",
            "illi_data size: 1623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_tags(dataset, filters):\n",
        "    filtered = []\n",
        "    for doc in dataset:\n",
        "        for label in doc[\"labels\"]:\n",
        "            if label[2:] in filters:\n",
        "                filtered.append(doc)\n",
        "                break\n",
        "    print(f\"Filters:{filters}:{len(filtered)}\")\n",
        "    return filtered"
      ],
      "metadata": {
        "id": "dFNam1K8wxDy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Train Splits"
      ],
      "metadata": {
        "id": "yys_YEqQsjZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STRATIFIED_COLUMNS = ['I-URL_PERSONAL',\n",
        "                        'I-ID_NUM',\n",
        "                        'B-STREET_ADDRESS',\n",
        "                        'B-PHONE_NUM',\n",
        "                        'B-USERNAME',\n",
        "                        'I-PHONE_NUM',\n",
        "                        'I-STREET_ADDRESS',\n",
        "                        'B-EMAIL',\n",
        "                        'B-ID_NUM',\n",
        "                        'B-URL_PERSONAL',\n",
        "                        'I-NAME_STUDENT',\n",
        "                        'B-NAME_STUDENT',\n",
        "                        'O'] # stratified labels with order\n",
        "SPLITS = 5 #number of folds\n",
        "SAVE_DIR = \".\" # folder to save the k folds json files\n",
        "\n",
        "\n",
        "def create_stratified_folds(data, n_split=SPLITS, stratified_labels=STRATIFIED_COLUMNS):\n",
        "    \"\"\"\n",
        "    Create stratified folds for cross-validation based on specified columns.\n",
        "\n",
        "    Args:\n",
        "        data (list): A list of dictionaries where each dictionary represents a sample.\n",
        "        n_split (int, optional): Number of splits/folds to create. Defaults to SPLITS.\n",
        "        stratified_labels (list, optional): List of labels to stratify the folds on. Defaults to STRATIFIED_COLUMNS.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys represent the fold numbers (as strings) and values\n",
        "              are lists containing the documents assigned to each fold.\n",
        "    \"\"\"\n",
        "    processed = set()\n",
        "    folds = {str(i):[] for i in range(n_split)}\n",
        "\n",
        "    for label in stratified_labels:\n",
        "        docs = []\n",
        "        for sample in data:\n",
        "            if label in sample['labels']:\n",
        "\n",
        "                #don't process document more than once\n",
        "                if sample['document'] not in processed:\n",
        "                    docs.append(sample['document'])\n",
        "                    processed.add(sample['document'])\n",
        "\n",
        "        folds = distribute_docs(folds, docs)\n",
        "\n",
        "    return folds\n",
        "\n",
        "def create_document_fold_mapping(folds):\n",
        "    \"\"\"\n",
        "    Creates a mapping of documents to folds.\n",
        "\n",
        "    Args:\n",
        "    - folds (dict): A dictionary containing fold IDs as keys and lists of documents as values.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary mapping each document to its respective fold.\n",
        "    \"\"\"\n",
        "    document_fold_mapping = {}\n",
        "    for fold, documents in folds.items():\n",
        "        for document in documents:\n",
        "            document_fold_mapping[document] = fold\n",
        "    return document_fold_mapping\n",
        "\n",
        "\n",
        "def distribute_docs(folds, doc_id):\n",
        "    \"\"\"\n",
        "    Distributes document IDs equally among the folds in the given dictionary.\n",
        "\n",
        "    Args:\n",
        "    - folds (dict): A dictionary containing fold IDs as keys and empty lists as values.\n",
        "    - doc_id (list): A list of document IDs to be distributed among the folds.\n",
        "\n",
        "    Returns:\n",
        "    dict: The modified folds dictionary with document IDs distributed equally among the folds.\n",
        "    \"\"\"\n",
        "    combined_list = [item for sublist in folds.values() for item in sublist]\n",
        "\n",
        "    num_folds = len(folds)\n",
        "    chunk_size = len(doc_id) // num_folds\n",
        "    remainder = len(doc_id) % num_folds\n",
        "\n",
        "    for i in range(num_folds):\n",
        "        start_idx = i * chunk_size + min(i, remainder)\n",
        "        end_idx = (i + 1) * chunk_size + min(i + 1, remainder)\n",
        "        folds[str(i)] += doc_id[start_idx:end_idx]\n",
        "\n",
        "    new_combined_list = [item for sublist in folds.values() for item in sublist]\n",
        "\n",
        "    return folds\n",
        "\n",
        "\n",
        "def create_ksplits(data, document_fold_dict):\n",
        "    \"\"\"\n",
        "    Split data samples into k splits based on pre-defined document fold dictionary.\n",
        "\n",
        "    Args:\n",
        "        data (list): A list of dictionaries where each dictionary represents a sample.\n",
        "        document_fold_dict (dict): A dictionary where keys are document IDs and values\n",
        "                                   represent the fold ID assigned to the document.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys represent the split numbers (as strings) and values\n",
        "              are lists containing the samples assigned to each split.\n",
        "    \"\"\"\n",
        "    splits = {str(i):[] for i in range(SPLITS)}\n",
        "\n",
        "    for sample in data:\n",
        "        doc_id = sample['document']\n",
        "        fold_id = document_fold_dict[doc_id]\n",
        "        splits[fold_id].append(sample)\n",
        "\n",
        "    return splits\n",
        "\n"
      ],
      "metadata": {
        "id": "NnrD81T9xuFd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = json.load(open(base_location+\"train.json\"))\n",
        "folds = create_stratified_folds(train)\n",
        "document_fold_dict = create_document_fold_mapping(folds)\n",
        "train_splits = create_ksplits(train, document_fold_dict)\n",
        "\n",
        "suplimentary_splits = [\n",
        "    nicollas,\n",
        "    mpware,\n",
        "    moth,\n",
        "    pj,\n",
        "    illi_data\n",
        "]\n"
      ],
      "metadata": {
        "id": "s6WYfYV0xyD8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_B_only(dataset):\n",
        "    filtered = []\n",
        "    excluded = []\n",
        "    for doc in dataset:\n",
        "        is_student = False\n",
        "        is_i = False\n",
        "        for label in doc[\"labels\"]:\n",
        "            if \"NAME_STUDENT\" in label:\n",
        "                is_student = True\n",
        "            if label == \"I-NAME_STUDENT\":\n",
        "                is_i = True\n",
        "        if is_student and not is_i:\n",
        "            excluded.append(doc)\n",
        "            continue\n",
        "        filtered.append(doc)\n",
        "    return filtered, excluded"
      ],
      "metadata": {
        "id": "3MsXafbOx3aw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_original = json.load(open(base_location+\"train.json\"))\n",
        "def replace_test_docs(test_set):\n",
        "    original = []\n",
        "    for doc in test_set:\n",
        "        for each in train_original:\n",
        "            if doc[\"document\"] == each[\"document\"]:\n",
        "                original.append(each)\n",
        "                break\n",
        "    return original"
      ],
      "metadata": {
        "id": "yuw4FiWIx6n2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = []\n",
        "no_of_splits = SPLITS\n",
        "\n",
        "for i in range(no_of_splits):\n",
        "    test_set = []\n",
        "    train_set = []\n",
        "    for j in range(no_of_splits):\n",
        "        if i == j:\n",
        "            test_set = train_splits[str(j)]\n",
        "            train_set +=  suplimentary_splits[j]\n",
        "        else:\n",
        "            train_set += train_splits[str(j)]\n",
        "\n",
        "    splits.append((train_set, test_set))"
      ],
      "metadata": {
        "id": "5_lqm3cVx8q6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_english_word(word, debug=False):\n",
        "    word = word.strip()\n",
        "    if len(word)<2:\n",
        "        return True\n",
        "\n",
        "    if word.istitle():\n",
        "        return False\n",
        "\n",
        "    word = word.lower()\n",
        "\n",
        "    lemma1 = lemmatizer.lemmatize(word, 'v')\n",
        "    lemma2 = lemmatizer.lemmatize(word, 'n')\n",
        "    lemma3 = lemmatizer.lemmatize(word, 'a')\n",
        "    lemma4 = lemmatizer.lemmatize(word, 'r')\n",
        "    lemma5 = lemmatizer.lemmatize(word, 's')\n",
        "\n",
        "    lemmas = set([lemma1, lemma2, lemma3, lemma4, lemma5])\n",
        "\n",
        "    for lemma in lemmas:\n",
        "        if lemma in english_words:\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "english_words = set(words.words())\n",
        "english_words=english_words.union(enable_eng_wordlist)\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "aDIg-3mExbU1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = ['B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT','B-PHONE_NUM','B-STREET_ADDRESS','B-URL_PERSONAL','B-USERNAME',\n",
        "              'I-ID_NUM','I-NAME_STUDENT','I-PHONE_NUM','I-STREET_ADDRESS','I-URL_PERSONAL','O']"
      ],
      "metadata": {
        "id": "ItSn7nrmxcFL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = sorted(all_labels)\n",
        "label2id = {l: i for i,l in enumerate(all_labels)}\n",
        "id2label = {v:k for k,v in label2id.items()}\n",
        "print(id2label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsJ8BE5kxedm",
        "outputId": "01b56d6e-6b00-4ac1-d1ca-ea326965754d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'B-EMAIL', 1: 'B-ID_NUM', 2: 'B-NAME_STUDENT', 3: 'B-PHONE_NUM', 4: 'B-STREET_ADDRESS', 5: 'B-URL_PERSONAL', 6: 'B-USERNAME', 7: 'I-ID_NUM', 8: 'I-NAME_STUDENT', 9: 'I-PHONE_NUM', 10: 'I-STREET_ADDRESS', 11: 'I-URL_PERSONAL', 12: 'O'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = ['B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT','B-PHONE_NUM','B-STREET_ADDRESS','B-URL_PERSONAL','B-USERNAME',\n",
        "          'I-ID_NUM','I-NAME_STUDENT','I-PHONE_NUM','I-STREET_ADDRESS','I-URL_PERSONAL'\n",
        "         ]"
      ],
      "metadata": {
        "id": "dfUohvv1x-mU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(example, tokenizer, label2id):\n",
        "    text = []\n",
        "\n",
        "    # these are at the character level\n",
        "    labels = []\n",
        "    targets = []\n",
        "\n",
        "    for t, l, ws in zip(example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]):\n",
        "\n",
        "        text.append(t)\n",
        "        labels.extend([l]*len(t))\n",
        "\n",
        "        if l in target:\n",
        "            targets.append(1)\n",
        "        else:\n",
        "            targets.append(0)\n",
        "        # if there is trailing whitespace\n",
        "        if ws:\n",
        "            text.append(\" \")\n",
        "            labels.append(fill_label)\n",
        "\n",
        "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=TRAINING_MAX_LENGTH)\n",
        "\n",
        "    target_num = sum(targets)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    text = \"\".join(text)\n",
        "    token_labels = []\n",
        "\n",
        "    for start_idx, end_idx in tokenized.offset_mapping:\n",
        "\n",
        "        # CLS token\n",
        "        if start_idx == 0 and end_idx == 0:\n",
        "            token_labels.append(label2id[fill_label])\n",
        "            continue\n",
        "\n",
        "        # case when token starts with whitespace\n",
        "        if text[start_idx].isspace():\n",
        "            start_idx += 1\n",
        "\n",
        "        token_labels.append(label2id[labels[start_idx]])\n",
        "\n",
        "    length = len(tokenized.input_ids)\n",
        "\n",
        "    return {\n",
        "        **tokenized,\n",
        "        \"labels\": token_labels,\n",
        "        \"length\": length,\n",
        "        \"target_num\": target_num,\n",
        "        \"group\": 1 if target_num>0 else 0\n",
        "    }"
      ],
      "metadata": {
        "id": "4GbGZzroyAhs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relabel(doc):  # Calculate once outside the loop\n",
        "    pred_labels = doc[\"predicted_labels\"]\n",
        "    for i, label in enumerate(doc[\"labels\"]):\n",
        "        try:\n",
        "            if label < base_labels and label != pred_labels[i]:\n",
        "                # Update the label only once per condition\n",
        "                doc[\"labels\"][i] = label2id['O-'+id2label[label]]\n",
        "        except:\n",
        "            print(d_idx, len(item[\"labels\"]),len(pred_labels) )\n",
        "    return doc\n"
      ],
      "metadata": {
        "id": "BVYfYJR5yCx0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ds(data):\n",
        "    ds = Dataset.from_dict({\n",
        "        \"tokens\": [x[\"tokens\"] for x in data],\n",
        "        \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n",
        "        \"provided_labels\": [x[\"labels\"] for x in data],\n",
        "    })\n",
        "    ds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id}, num_proc=cpu_cores)\n",
        "    ds = ds.class_encode_column(\"group\")\n",
        "    return ds"
      ],
      "metadata": {
        "id": "CN9tA2Z9yFBO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import recall_score, precision_score\n",
        "from seqeval.metrics import classification_report\n",
        "from seqeval.metrics import f1_score\n",
        "\n",
        "def compute_metrics(p, all_labels):\n",
        "    predictions, labels = p\n",
        "    if type(predictions)==tuple:\n",
        "        predictions=predictions[0]\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    ignore_indices = [-100]\n",
        "    true_predictions = [\n",
        "        [all_labels[p] for (p, l) in zip(prediction, label) if l not in ignore_indices]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [all_labels[l] for (p, l) in zip(prediction, label) if l not in ignore_indices]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    recall = recall_score(true_labels, true_predictions)\n",
        "    precision = precision_score(true_labels, true_predictions)\n",
        "    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
        "\n",
        "    ignore_indices_insample = [label2id[\"O\"], -100]\n",
        "    true_predictions_insample = [\n",
        "        [all_labels[p] for (p, l) in zip(prediction, label) if l not in ignore_indices_insample]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels_insample = [\n",
        "        [all_labels[l] for (p, l) in zip(prediction, label) if l not in ignore_indices_insample]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    recall_insample = recall_score(true_labels_insample, true_predictions_insample)\n",
        "    precision_insample = precision_score(true_labels_insample, true_predictions_insample)\n",
        "    f1_score_insample = (1 + 5*5) * recall_insample * precision_insample / (5*5*precision_insample + recall_insample)\n",
        "\n",
        "    results = {\n",
        "        'recall': recall,\n",
        "        'precision': precision,\n",
        "        'f1': f1_score,\n",
        "        'recall_insample': recall_insample,\n",
        "        'precision_insample': precision_insample,\n",
        "        'f1_insample': f1_score_insample\n",
        "    }\n",
        "    return results"
      ],
      "metadata": {
        "id": "yMyzftjwyGvt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get SpaCy tokens with their character positions\n",
        "def get_token_positions(doc):\n",
        "    start= 0\n",
        "    positions = []\n",
        "    i = 1\n",
        "    text = \"\"\n",
        "    for token, whitespace in zip(doc[\"tokens\"], doc[\"trailing_whitespace\"]):\n",
        "        text += token + [\"\", \" \"][whitespace]\n",
        "        position = (i, token, start, start+len(token))\n",
        "        start=len(text)\n",
        "        positions.append(position)\n",
        "        i+=1\n",
        "    return text, positions\n",
        "\n",
        "\n",
        "def process_cluster(cluster, final_labels):\n",
        "    if len(cluster) <= 2:\n",
        "        return final_labels\n",
        "    else:\n",
        "        print(cluster)\n",
        "    \"\"\"\n",
        "    if cluster[0][1] == 'B-URL_PERSONAL':\n",
        "        fill_label = labels2id['I-URL_PERSONAL']\n",
        "        for i in range(cluster[1][0], cluster[-1][0]):\n",
        "            final_labels[i] = fill_label\n",
        "        return final_labels\n",
        "    el\n",
        "    \"\"\"\n",
        "    return final_labels\n",
        "\n",
        "\n",
        "def decode_labels(text, positions, predictions, offset_mapping, eng_tok=True, smooth=True):\n",
        "    results = []\n",
        "    final_labels = []\n",
        "    last_position = 0\n",
        "    assert len(predictions) == len(offset_mapping), \"Offsets and predictions doesn't match!\"\n",
        "    for count, token, token_start, token_end in positions:\n",
        "        labels = []\n",
        "        text_chunk = \"\"\n",
        "        if eng_tok and is_english_word(token): # Pre-filter with 0.994 recall\n",
        "            labels.append(label2id[\"O\"])\n",
        "        else:\n",
        "            for i in range(last_position, len(offset_mapping)):\n",
        "                offset_start, offset_end = offset_mapping[i]\n",
        "                label = predictions[i]\n",
        "                if token_start <= offset_end and token_end > offset_start:\n",
        "                    labels.append(label)\n",
        "                    last_position = i\n",
        "                    text_chunk += text[offset_start:offset_end]\n",
        "                elif offset_start > token_end:\n",
        "                    break\n",
        "        prediction = label2id[\"O\"]\n",
        "        labels = np.array(labels)\n",
        "        labels=labels[labels!=label2id[\"O\"]]\n",
        "        if labels.size!=0:\n",
        "            prediction = mode(labels)\n",
        "        results.append((count, token, text_chunk, token_start, token_end, prediction))\n",
        "        final_labels.append(prediction)\n",
        "\n",
        "    # Smooth out labels\n",
        "    if smooth:\n",
        "        for i in range(1, len(final_labels)-1):\n",
        "            pre_label = id2label[final_labels[i-1]][1:]\n",
        "            post_label = id2label[final_labels[i+1]][1:]\n",
        "            stripped_token = results[i][1].strip(\"\\n -,:[]';/?.><,()-_+*#|\\\\r\\t'\")\n",
        "            if len(stripped_token)==0 and \"STREET\" in post_label and \"STREET\" in pre_label:\n",
        "                final_labels[i] = final_labels[i+1]\n",
        "\n",
        "    return results, torch.tensor(final_labels, dtype=int)"
      ],
      "metadata": {
        "id": "wuHpICw3yIoL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import recall_score, precision_score\n",
        "from seqeval.metrics import classification_report\n",
        "from seqeval.metrics import f1_score\n",
        "from statistics import mode\n",
        "\n",
        "def evaluate_simple(predictions, labels, all_labels):\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    ignore_indices = [-100]\n",
        "    true_predictions = [\n",
        "        [all_labels[p] for (p, l) in zip(prediction, label) if l not in ignore_indices]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [all_labels[l] for (p, l) in zip(prediction, label) if l not in ignore_indices]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    recall = recall_score(true_labels, true_predictions)\n",
        "    precision = precision_score(true_labels, true_predictions)\n",
        "    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
        "\n",
        "    results = {\n",
        "        'recall': recall,\n",
        "        'precision': precision,\n",
        "        'f1': f1_score\n",
        "    }\n",
        "    return results"
      ],
      "metadata": {
        "id": "Cs4wEdnnyKU-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "class PRFScore:\n",
        "    \"\"\"A precision / recall / F score.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        tp: int = 0,\n",
        "        fp: int = 0,\n",
        "        fn: int = 0,\n",
        "    ) -> None:\n",
        "        self.tp = tp\n",
        "        self.fp = fp\n",
        "        self.fn = fn\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.tp + self.fp + self.fn\n",
        "\n",
        "    def __iadd__(self, other):  # in-place add\n",
        "        self.tp += other.tp\n",
        "        self.fp += other.fp\n",
        "        self.fn += other.fn\n",
        "        return self\n",
        "\n",
        "    def __add__(self, other):\n",
        "        return PRFScore(\n",
        "            tp=self.tp + other.tp, fp=self.fp + other.fp, fn=self.fn + other.fn\n",
        "        )\n",
        "\n",
        "    def score_set(self, cand: set, gold: set) -> None:\n",
        "        self.tp += len(cand.intersection(gold))\n",
        "        self.fp += len(cand - gold)\n",
        "        self.fn += len(gold - cand)\n",
        "\n",
        "    @property\n",
        "    def precision(self) -> float:\n",
        "        return self.tp / (self.tp + self.fp + 1e-100)\n",
        "\n",
        "    @property\n",
        "    def recall(self) -> float:\n",
        "        return self.tp / (self.tp + self.fn + 1e-100)\n",
        "\n",
        "    @property\n",
        "    def f1(self) -> float:\n",
        "        p = self.precision\n",
        "        r = self.recall\n",
        "        return 2 * ((p * r) / (p + r + 1e-100))\n",
        "\n",
        "    @property\n",
        "    def f5(self) -> float:\n",
        "        beta = 5\n",
        "        p = self.precision\n",
        "        r = self.recall\n",
        "\n",
        "        fbeta = (1+(beta**2))*p*r / ((beta**2)*p + r + 1e-100)\n",
        "        return fbeta\n",
        "\n",
        "    def to_dict(self) -> Dict[str, float]:\n",
        "        return {\"p\": self.precision, \"r\": self.recall, \"f5\": self.f5}\n",
        "\n",
        "\n",
        "def compute_metrics_eval(pred_df, gt_df):\n",
        "    \"\"\"\n",
        "    Compute the LB metric (lb) and other auxiliary metrics\n",
        "    \"\"\"\n",
        "\n",
        "    references = {(row.document, row.token, row.label) for row in gt_df.itertuples()}\n",
        "    predictions = {(row.document, row.token, row.label) for row in pred_df.itertuples()}\n",
        "\n",
        "    score_per_type = defaultdict(PRFScore)\n",
        "    references = set(references)\n",
        "\n",
        "    for ex in predictions:\n",
        "        pred_type = ex[-1] # (document, token, label)\n",
        "        if pred_type != 'O':\n",
        "            pred_type = pred_type[2:] # avoid B- and I- prefix\n",
        "\n",
        "        if pred_type not in score_per_type:\n",
        "            score_per_type[pred_type] = PRFScore()\n",
        "\n",
        "        if ex in references:\n",
        "            score_per_type[pred_type].tp += 1\n",
        "            references.remove(ex)\n",
        "        else:\n",
        "            score_per_type[pred_type].fp += 1\n",
        "\n",
        "    for doc, tok, ref_type in references:\n",
        "        if ref_type != 'O':\n",
        "            ref_type = ref_type[2:] # avoid B- and I- prefix\n",
        "\n",
        "        if ref_type not in score_per_type:\n",
        "            score_per_type[ref_type] = PRFScore()\n",
        "        score_per_type[ref_type].fn += 1\n",
        "\n",
        "    totals = PRFScore()\n",
        "\n",
        "    for prf in score_per_type.values():\n",
        "        totals += prf\n",
        "\n",
        "    return {\n",
        "        \"ents_p\": totals.precision,\n",
        "        \"ents_r\": totals.recall,\n",
        "        \"ents_f5\": totals.f5,\n",
        "        \"ents_per_type\": {k: v.to_dict() for k, v in score_per_type.items() if k!= 'O'},\n",
        "    }"
      ],
      "metadata": {
        "id": "xXV1T0IlyM2t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_labels(data):\n",
        "    final_preds = []\n",
        "    model.eval()\n",
        "    for example in tqdm(data):\n",
        "        text, positions = get_token_positions(example)\n",
        "        tokens = tokenizer(text, return_offsets_mapping=True,  return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            rs = model(**{k:tokens[k].to(device) for k in [\"input_ids\", \"token_type_ids\", \"attention_mask\"]})\n",
        "        offset_mapping = tokens[\"offset_mapping\"][0].tolist()[1:-1]  # Get offset mappings\n",
        "        predictions = (rs.logits[0,:,:].argmax(-1)).to(int).tolist()\n",
        "        final_preds.append(predictions)\n",
        "    return final_preds"
      ],
      "metadata": {
        "id": "fMWyHKdnyOmO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from transformers import TrainerCallback\n",
        "\n",
        "class CustomCrossEntropyLossWithFN(nn.Module):\n",
        "    def __init__(self, weights):\n",
        "        super().__init__()\n",
        "        self.weights = torch.tensor(weights).to('cuda')\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # Standard cross-entropy loss\n",
        "        return F.cross_entropy(logits, targets, weight=self.weights)\n",
        "\n",
        "# Create a custom Trainer class\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "         # Unpack inputs and get the model outputs\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Access the labels from inputs\n",
        "        labels = inputs[\"labels\"].view(-1).clone()\n",
        "\n",
        "        # Determine the percentage of class 12 labels to drop\n",
        "        drop_percentage = 0.30  # for example, 20%\n",
        "\n",
        "        # Find indices where the labels are class 12\n",
        "        class_12_indices = (labels == 12).nonzero(as_tuple=True)\n",
        "\n",
        "        # Calculate how many labels to drop\n",
        "        num_to_drop = int(drop_percentage * len(class_12_indices[0]))\n",
        "\n",
        "        # Randomly choose indices of class 12 labels to set to ignore index (-100)\n",
        "        drop_indices = class_12_indices[0][torch.randperm(len(class_12_indices[0]))[:num_to_drop]]\n",
        "        labels[drop_indices] = -100  # -100 is commonly used as the ignore index in PyTorch\n",
        "\n",
        "        # Compute the loss using the potentially modified labels\n",
        "        custom_loss = CustomCrossEntropyLossWithFN(self.class_weights)(\n",
        "            logits.view(-1, len(all_labels)), labels\n",
        "        )\n",
        "\n",
        "        # Return loss (and optionally outputs)\n",
        "        return (custom_loss, outputs) if return_outputs else custom_loss\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        self.class_weights = weights\n",
        "\n",
        "class CustomAfterEvalCallback(TrainerCallback):\n",
        "    def on_evaluate(self, args, state, control, **kwargs):\n",
        "        optimizer.train()\n",
        "\n",
        "class CustomBeforeTrainCallback(TrainerCallback):\n",
        "    def on_train_begin(self, args, state, control, **kwargs):\n",
        "        optimizer.train()\n",
        "\n",
        "class CustomBeforeEvalCallback(TrainerCallback):\n",
        "    def on_evaluate_begin(self, args, state, control, **kwargs):\n",
        "        optimizer.eval()\n"
      ],
      "metadata": {
        "id": "UViY3eWIyQuu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trainer(ds_train, ds_test, optimizer, epochs=5, save_limit=1, acc=1, es=100, ss=100):\n",
        "    args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        fp16=False,\n",
        "        num_train_epochs=epochs,\n",
        "        per_device_train_batch_size=1,\n",
        "        per_device_eval_batch_size=1,\n",
        "        gradient_accumulation_steps=acc,\n",
        "        report_to=\"none\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        warmup_steps=es, ##\n",
        "        learning_rate=2e-5, ##\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=save_limit,\n",
        "        overwrite_output_dir=True,\n",
        "        load_best_model_at_end=True,\n",
        "        lr_scheduler_type='cosine', ##\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        seed=42,\n",
        "        weight_decay = 0.01 ##\n",
        "    )\n",
        "    trainer = CustomTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=ds_train,\n",
        "        eval_dataset=ds_test,\n",
        "        data_collator=collator,\n",
        "        tokenizer=tokenizer,\n",
        "        #optimizers=(optimizer, None) ,\n",
        "        compute_metrics=partial(compute_metrics, all_labels=all_labels),\n",
        "        #callbacks=[CustomBeforeTrainCallback, CustomAfterEvalCallback, CustomBeforeEvalCallback]\n",
        "    )\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "Mk-FagwbySaP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)"
      ],
      "metadata": {
        "id": "HsR7J4tNyUHc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Training"
      ],
      "metadata": {
        "id": "MYeMmogitKnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "FREEZE_LAYERS_STEP2 = 6\n",
        "skip_splits = []\n",
        "for split, (train_split, test_split) in enumerate(splits):\n",
        "    if split in skip_splits:\n",
        "        continue\n",
        "\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        TRAINING_MODEL_PATH,\n",
        "        num_labels=len(all_labels),\n",
        "        id2label=id2label,\n",
        "        label2id=label2id,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "\n",
        "\n",
        "    if FREEZE_LAYERS_STEP2>0:\n",
        "        print(f'Freezing {FREEZE_LAYERS_STEP2} layers.')\n",
        "        for layer in model.deberta.encoder.layer[:FREEZE_LAYERS_STEP2]:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    ds_train = get_ds(train_split)\n",
        "    ds_test = get_ds(test_split)\n",
        "    k=1\n",
        "    acc=64/k\n",
        "    ws = int(len(train_split)/(2*acc*k))\n",
        "    optimizer = None\n",
        "\n",
        "    trainer = get_trainer(ds_train.shuffle(seed=42), ds_test, optimizer, epochs=5, save_limit=1, acc=acc, es=ws, ss=ws)\n",
        "    weights = [1.0]*(len(all_labels)-1)+[0.01]\n",
        "    trainer.set_weights(weights)\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model(f\"{base_location}pretrained_models/split{split}_deberta_v3_large_2stepped\")\n",
        "    del trainer, model, ds_train, ds_test\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "g7w4bG3JyWTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model and evaluate"
      ],
      "metadata": {
        "id": "TLlQXmwRtOtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "split=1\n",
        "model = AutoModelForTokenClassification.from_pretrained(f\"{base_location}pretrained_models/split{split}_deberta_v3_large_2stepped\")\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "ojUr0dgu6-l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cuda\"\n",
        "count=1\n",
        "final_targets = []\n",
        "final_preds = []\n",
        "final_results = []\n",
        "pred_dict = {\n",
        "    \"document\":[],\n",
        "    \"token\":[],\n",
        "    \"label\":[]\n",
        "}\n",
        "target_dict = {\n",
        "    \"document\":[],\n",
        "    \"token\":[],\n",
        "    \"label\":[]\n",
        "}\n",
        "for example in tqdm(splits[split][1]):\n",
        "    text, positions = get_token_positions(example)\n",
        "    tokens = tokenizer(text, return_offsets_mapping=True,  return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        rs = model(**{k:tokens[k].to(device) for k in [\"input_ids\", \"token_type_ids\", \"attention_mask\"]})\n",
        "    offset_mapping = tokens[\"offset_mapping\"][0].tolist()[1:-1]  # Get offset mappings\n",
        "    predictions = rs[\"logits\"][0,1:-1,:].argmax(-1).to(int).tolist()\n",
        "    _, final_labels = decode_labels(text, positions, predictions, offset_mapping)\n",
        "    targets = torch.tensor([label2id[l] for l in example[\"labels\"]], dtype=int)\n",
        "    final_targets.append(targets)\n",
        "    final_preds.append(final_labels)\n",
        "    final_results.append(_)\n",
        "\n",
        "    pred_dict[\"document\"] +=[count]*len(final_labels)\n",
        "    target_dict[\"document\"] +=[count]*len(final_labels)\n",
        "\n",
        "    pred_dict[\"token\"] +=list(range(1, len(targets)+1))\n",
        "    target_dict[\"token\"] +=list(range(1, len(targets)+1))\n",
        "\n",
        "    pred_dict[\"label\"] +=final_labels\n",
        "    target_dict[\"label\"] +=targets\n",
        "    count+=1\n",
        "    del tokens\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "pred_dict_filtered = {\n",
        "    \"document\":[],\n",
        "    \"token\":[],\n",
        "    \"label\":[]\n",
        "}\n",
        "\n",
        "target_dict_filtered = {\n",
        "    \"document\":[],\n",
        "    \"token\":[],\n",
        "    \"label\":[]\n",
        "}\n",
        "for i in range(len(pred_dict[\"label\"])):\n",
        "    pred_dict[\"label\"][i] = id2label[pred_dict[\"label\"][i].item()]\n",
        "    if pred_dict[\"label\"][i] != 'O':\n",
        "        pred_dict_filtered[\"document\"].append(pred_dict[\"document\"][i] )\n",
        "        pred_dict_filtered[\"token\"].append(pred_dict[\"token\"][i] )\n",
        "        pred_dict_filtered[\"label\"].append(pred_dict[\"label\"][i] )\n",
        "\n",
        "for i in range(len(target_dict[\"label\"])):\n",
        "    target_dict[\"label\"][i] = id2label[target_dict[\"label\"][i].item()]\n",
        "    if target_dict[\"label\"][i] != 'O':\n",
        "        target_dict_filtered[\"document\"].append(target_dict[\"document\"][i] )\n",
        "        target_dict_filtered[\"token\"].append(target_dict[\"token\"][i] )\n",
        "        target_dict_filtered[\"label\"].append(target_dict[\"label\"][i] )\n",
        "\n",
        "pred_df = pd.DataFrame(pred_dict_filtered)\n",
        "gt_df = pd.DataFrame(target_dict_filtered)\n",
        "eval_dict = compute_metrics_eval(pred_df, gt_df)\n",
        "m = eval_dict['ents_f5']\n",
        "print(f\"LB = {round(m, 6)}\")\n",
        "eval_dict"
      ],
      "metadata": {
        "id": "TxRGCH99OM40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "oMMuYYZcOmkm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}